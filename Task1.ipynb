{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0115a9f-1893-4b51-93ae-8daae1aca5db",
   "metadata": {},
   "source": [
    "Student id - 24205067  \n",
    "Dataset - Dublin Rentals - http://mlg.ucd.ie/modules/python/assignment1/rental/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0935d2f6-af16-4a84-89ba-4eb10b4b15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import time\n",
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd39ab2-040e-47fa-86b3-e6e6850ba0c4",
   "metadata": {},
   "source": [
    "### Prepare the URL for web scraping -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af111604-531a-46f4-9f98-36864584f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the rental pages\n",
    "BASE_URL = 'http://mlg.ucd.ie/modules/python/assignment1/rental/'\n",
    "# Main page URL\n",
    "MAIN_PAGE_URL = BASE_URL + 'index.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11533fa-5d93-4c11-b5cd-8300037570e9",
   "metadata": {},
   "source": [
    "### Use `urllib` to fetch and return the html content as string -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3df1814d-66d5-4127-b3ce-17d489c36123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html = response.read().decode() \n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c7581-be29-43d5-8d6f-4923e56ba0eb",
   "metadata": {},
   "source": [
    "### 1. `get_quarter_links` function\n",
    "This function scrapes the **main page URL** to find links for each quarter’s first page.\n",
    "\n",
    "- Downloads the HTML of the main page\n",
    "- Finds the relevant `<div>` blocks and anchor tags\n",
    "- Builds a dictionary mapping each quarter identifier (e.g., `Q1`, `Q2`, etc.) to the quarter’s first page URL\n",
    "\n",
    "This dictionary will be used later to start scraping for each quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b279b5b-d05e-4306-9f4e-5905edde6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter_links(main_page_url):\n",
    "    html = get_html(main_page_url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    quarter_links = {}\n",
    "\n",
    "    # We get all <div> elements with id=\"content\" and class \"col-md-12\", which stores the links to  different quarters, as identified \n",
    "    # from the source html\n",
    "    content_divs = soup.find_all(\"div\", {\"id\": \"content\", \"class\": \"col-md-12\"})\n",
    "    \n",
    "    # Then we iterate over the divs and choose the one that contains the quarter links (identified by an <h4> tag)\n",
    "    for div in content_divs:\n",
    "        if div.find(\"h4\"):\n",
    "            # Now find all inner div tags containing the quarter links\n",
    "            for sub_div in div.find_all(\"div\"):\n",
    "                a_tag = sub_div.find(\"a\")\n",
    "                if a_tag and a_tag.get(\"href\"):\n",
    "                    href = a_tag[\"href\"]\n",
    "                    # Extract quarter identifier from URL, e.g., \"Q1\" from \"Q1-page01.html\"\n",
    "                    quarter = href.split(\"-\")[0]\n",
    "                    full_url = urllib.request.urljoin(main_page_url, href)\n",
    "                    quarter_links[quarter] = full_url\n",
    "            break  # stop once the correct div is found\n",
    "    return quarter_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fcb76-171d-4f4b-b330-517d02b2b2d8",
   "metadata": {},
   "source": [
    "### 2. `get_total_pages` function\n",
    "For each quarter’s first page, this function figures out how many pages of data exist.\n",
    "\n",
    "- Loads the first page of the quarter\n",
    "- Looks for a header (e.g., `Rentals: Q1 — Page 1 of 26`)\n",
    "- Extracts the total number of pages from the text\n",
    "\n",
    "These pages will be used in a later step to dynamically create the page URLs scrape them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0ce7205-8aae-4c29-a4f5-5b0cb619ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_pages(quarter_first_page_url):\n",
    "    html = get_html(quarter_first_page_url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    h2_tag = soup.find(\"h2\")\n",
    "    total_pages = 1  # default if not found\n",
    "    if h2_tag:\n",
    "        text = h2_tag.get_text(strip=True)\n",
    "        # We split on 'of' and take the second part of the string for number of pages\n",
    "        if \"of\" in text:\n",
    "            try:\n",
    "                total_pages = int(text.split(\"of\")[-1].strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return total_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5e980-426b-46d8-9447-d7aec79b9bfc",
   "metadata": {},
   "source": [
    "### 3. `scrape_rental_page` function\n",
    "Given a single page URL -\n",
    "\n",
    "- Downloads the HTML\n",
    "- Finds each `<li>` block that corresponds to a rental record\n",
    "- Extracts the date and table of rental details\n",
    "- Compiles them into a list of dictionaries, one dictionary per record\n",
    "\n",
    "We’ll call this repeatedly for each page within a quarter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "819bc994-c838-4d9a-90f6-ea7e1992d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_rental_page(page_url):\n",
    "    html = get_html(page_url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    records_data = []\n",
    "\n",
    "    # We need to find all the <li> tags that represent a rental record.\n",
    "    records = soup.find_all(\"li\")\n",
    "    for record in records:\n",
    "        # The span tag with class \"record\" stores the listing date.\n",
    "        date_span = record.find(\"span\", {\"class\": \"record\"})\n",
    "        if not date_span:\n",
    "            continue\n",
    "        record_date = date_span.text.strip()\n",
    "        \n",
    "        # The rest of the data is in the table with class \"rental\".\n",
    "        table = record.find(\"table\", {\"class\": \"rental\"})\n",
    "        if not table:\n",
    "            continue\n",
    "        \n",
    "        record_details = {\"Date\": record_date}\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            field_td = row.find(\"td\", {\"class\": \"field\"})\n",
    "            if not field_td:\n",
    "                continue\n",
    "            # The field names contain ':' so we need to clean the field name by removing any colon.\n",
    "            field_name = field_td.text.strip().replace(\":\", \"\")\n",
    "            # Get the second <td> as the field value. (Observed - 2 <td> per field to store the field name and value)\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) < 2:\n",
    "                continue\n",
    "            field_value = cells[1].text.strip()\n",
    "            record_details[field_name] = field_value\n",
    "        records_data.append(record_details)\n",
    "    return records_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1312b0-8df4-4153-9536-2fad745574c3",
   "metadata": {},
   "source": [
    "### 4. `scrape_quarter` function\n",
    "This function loops over all pages for a given quarter. For each page:\n",
    "\n",
    "- Builds a page-specific URL (e.g., `Q1-page01.html`, `Q1-page02.html`, etc.)\n",
    "- Scrapes the page with `scrape_rental_page`\n",
    "- Accumulates all records in a single list\n",
    "\n",
    "In the end, it returns a comprehensive list of records for that entire quarter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db4fa55-746e-4081-b8b8-19095a43df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_quarter(quarter, total_pages):\n",
    "    all_records = []\n",
    "    for page in range(1, total_pages + 1):\n",
    "        # Construct URL with page numbers (e.g., Q1-page04.html)\n",
    "        url = f\"{BASE_URL}{quarter}-page{page:02d}.html\"\n",
    "        print(f\"Scraping {url} ...\")\n",
    "        page_records = scrape_rental_page(url)\n",
    "        all_records.extend(page_records)\n",
    "        time.sleep(0.5)  # delay to avoid overwhelming the server\n",
    "    return all_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa01397f-97c4-47ab-bfad-26aefb9b95b5",
   "metadata": {},
   "source": [
    "### 5. `save_to_csv` function\n",
    "Once we’ve gathered all records, we can save them to a CSV. This function:\n",
    "\n",
    "- Takes a list of dictionaries (the rental records)\n",
    "- Identifies all the keys from the first dictionary\n",
    "- Writes out a CSV file with those keys as column headers\n",
    "\n",
    "Useful for storing the final combined dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d4509c-c3f1-4fde-ae75-4e1a2aaa0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(records, filename):\n",
    "    if not records:\n",
    "        print(\"No records to save.\")\n",
    "        return\n",
    "    keys = list(records[0].keys())\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "    print(f\"Records successfully saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04548a41-2e7f-4f89-96c6-1800d3effa8e",
   "metadata": {},
   "source": [
    "### 6. Main entry point\n",
    "Finally, we tie everything together:\n",
    "\n",
    "1. Get all quarter links from the main page\n",
    "2. For each quarter, figure out the total pages\n",
    "3. Scrape every page within that quarter, appending all results\n",
    "4. Tag each record with the quarter label\n",
    "5. Save everything to a single CSV\n",
    "\n",
    "If, for any reason, no quarter links are found, we exit early.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5393d2e-d30f-451c-8804-d1c120f09614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Q1 from http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page01.html\n",
      "Total pages for Q1: 26\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page01.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page02.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page03.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page04.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page05.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page06.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page07.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page08.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page09.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page10.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page11.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page12.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page13.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page14.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page15.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page16.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page17.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page18.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page19.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page20.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page21.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page22.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page23.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page24.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page25.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q1-page26.html ...\n",
      "Total records for Q1: 510\n",
      "\n",
      "Processing Q2 from http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page01.html\n",
      "Total pages for Q2: 26\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page01.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page02.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page03.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page04.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page05.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page06.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page07.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page08.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page09.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page10.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page11.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page12.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page13.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page14.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page15.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page16.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page17.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page18.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page19.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page20.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page21.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page22.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page23.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page24.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page25.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q2-page26.html ...\n",
      "Total records for Q2: 509\n",
      "\n",
      "Processing Q3 from http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page01.html\n",
      "Total pages for Q3: 26\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page01.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page02.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page03.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page04.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page05.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page06.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page07.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page08.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page09.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page10.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page11.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page12.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page13.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page14.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page15.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page16.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page17.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page18.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page19.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page20.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page21.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page22.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page23.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page24.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page25.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q3-page26.html ...\n",
      "Total records for Q3: 506\n",
      "\n",
      "Processing Q4 from http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page01.html\n",
      "Total pages for Q4: 22\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page01.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page02.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page03.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page04.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page05.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page06.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page07.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page08.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page09.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page10.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page11.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page12.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page13.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page14.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page15.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page16.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page17.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page18.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page19.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page20.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page21.html ...\n",
      "Scraping http://mlg.ucd.ie/modules/python/assignment1/rental/Q4-page22.html ...\n",
      "Total records for Q4: 425\n",
      "Records successfully saved to all_rental_records.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Scrape the main page for quarter links\n",
    "    quarter_links = get_quarter_links(MAIN_PAGE_URL)\n",
    "    if not quarter_links:\n",
    "        print(\"No quarter links found on the main page.\")\n",
    "        exit(1)\n",
    "    \n",
    "    all_records_combined = []\n",
    "    # Step 2: For each quarter, determine total pages, scrape the records,\n",
    "    for quarter, first_page_url in quarter_links.items():\n",
    "        print(f\"\\nProcessing {quarter} from {first_page_url}\")\n",
    "        total_pages = get_total_pages(first_page_url)\n",
    "        print(f\"Total pages for {quarter}: {total_pages}\")\n",
    "        records = scrape_quarter(quarter, total_pages)\n",
    "        # # Update - Added a new column 'Quarter', so that the data is easier to segregate based on Quarter\n",
    "        for record in records:\n",
    "            record[\"Quarter\"] = quarter\n",
    "        all_records_combined.extend(records)\n",
    "        print(f\"Total records for {quarter}: {len(records)}\")\n",
    "    \n",
    "    # Save all records into a common CSV file with the quarter information\n",
    "    save_to_csv(all_records_combined, \"all_rental_records.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
